<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Ultrasonic Data Transfer</title>
<style>
  *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

  body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background: #0a0e17;
    color: #e0e0e0;
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  .container {
    width: 100%;
    max-width: 600px;
    padding: 16px;
    display: flex;
    flex-direction: column;
    gap: 12px;
    flex: 1;
  }

  header {
    text-align: center;
    padding: 12px 0;
  }

  header h1 {
    font-size: 1.4em;
    color: #00d4ff;
    letter-spacing: 1px;
  }

  .status-bar {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 8px;
    margin-top: 6px;
    font-size: 0.85em;
  }

  .status-dot {
    width: 10px;
    height: 10px;
    border-radius: 50%;
    background: #555;
    transition: background 0.3s;
  }

  .status-dot.listening { background: #00ff88; box-shadow: 0 0 6px #00ff88; }
  .status-dot.sending { background: #ff8800; box-shadow: 0 0 6px #ff8800; }

  .visualizer-wrapper {
    background: #111827;
    border: 1px solid #1e293b;
    border-radius: 8px;
    padding: 8px;
  }

  canvas {
    width: 100%;
    height: 100px;
    display: block;
    border-radius: 4px;
  }

  .freq-labels {
    display: flex;
    justify-content: space-between;
    font-size: 0.65em;
    color: #667;
    padding: 2px 4px 0;
  }

  .messages {
    flex: 1;
    min-height: 180px;
    max-height: 40vh;
    overflow-y: auto;
    background: #111827;
    border: 1px solid #1e293b;
    border-radius: 8px;
    padding: 12px;
    display: flex;
    flex-direction: column;
    gap: 8px;
  }

  .messages:empty::before {
    content: 'No messages yet. Start listening and send a message from another device.';
    color: #445;
    font-style: italic;
    font-size: 0.85em;
  }

  .msg {
    padding: 8px 12px;
    border-radius: 8px;
    max-width: 85%;
    word-break: break-word;
    font-size: 0.9em;
    line-height: 1.4;
  }

  .msg.sent {
    background: #1a3a5c;
    align-self: flex-end;
    border-bottom-right-radius: 2px;
  }

  .msg.received {
    background: #1c2a1c;
    align-self: flex-start;
    border-bottom-left-radius: 2px;
  }

  .msg .meta {
    font-size: 0.7em;
    color: #667;
    margin-top: 4px;
  }

  .send-area {
    display: flex;
    gap: 8px;
  }

  .send-area input {
    flex: 1;
    padding: 10px 14px;
    border-radius: 8px;
    border: 1px solid #1e293b;
    background: #111827;
    color: #e0e0e0;
    font-size: 0.95em;
    outline: none;
  }

  .send-area input:focus { border-color: #00d4ff; }

  button {
    padding: 10px 18px;
    border-radius: 8px;
    border: none;
    cursor: pointer;
    font-size: 0.9em;
    font-weight: 600;
    transition: background 0.2s, opacity 0.2s;
  }

  button:disabled { opacity: 0.4; cursor: not-allowed; }

  .btn-send {
    background: #00d4ff;
    color: #0a0e17;
  }

  .btn-send:hover:not(:disabled) { background: #00b8e0; }

  .controls {
    display: flex;
    gap: 8px;
    justify-content: center;
    flex-wrap: wrap;
  }

  .btn-listen {
    background: #00ff88;
    color: #0a0e17;
  }

  .btn-listen:hover:not(:disabled) { background: #00dd77; }

  .btn-stop {
    background: #ff4466;
    color: #fff;
  }

  .btn-stop:hover:not(:disabled) { background: #dd3355; }

  .debug-log {
    font-size: 0.7em;
    color: #556;
    max-height: 60px;
    overflow-y: auto;
    padding: 4px 8px;
    background: #0d1117;
    border-radius: 4px;
    border: 1px solid #1e293b;
  }
</style>
</head>
<body>

<div class="container">
  <header>
    <h1>Ultrasonic Transfer</h1>
    <div class="status-bar">
      <div class="status-dot" id="statusDot"></div>
      <span id="statusText">Idle</span>
    </div>
  </header>

  <div class="visualizer-wrapper">
    <canvas id="spectrum"></canvas>
    <div class="freq-labels">
      <span>17.8 kHz</span>
      <span>18.5 kHz</span>
      <span>19.5 kHz</span>
    </div>
  </div>

  <div class="messages" id="messages"></div>

  <div class="send-area">
    <input type="text" id="msgInput" placeholder="Type a message..." maxlength="200" />
    <button class="btn-send" id="btnSend">Send</button>
  </div>

  <div class="controls">
    <button class="btn-listen" id="btnListen">Start Listening</button>
    <button class="btn-stop" id="btnStop" disabled>Stop</button>
  </div>

  <div class="debug-log" id="debugLog"></div>
</div>

<script>
(function() {
  'use strict';

  // ── Frequency Map ──
  const FREQ_START = 17800;
  const FREQ_STOP  = 17900;
  const FREQ_BASE  = 18000;
  const FREQ_STEP  = 100;
  const NUM_NIBBLES = 16;

  const TONE_MS_MARKER  = 150;
  const TONE_MS_NIBBLE  = 100;
  const GAP_MS          = 60;

  const FFT_SIZE    = 2048;
  const SAMPLE_RATE = 44100;

  // Frequency tolerance for detection (Hz)
  const FREQ_TOLERANCE = 40;

  // Minimum magnitude to consider a tone present
  const DETECT_THRESHOLD = 20;

  // ── DOM Elements ──
  const statusDot  = document.getElementById('statusDot');
  const statusText = document.getElementById('statusText');
  const messagesEl = document.getElementById('messages');
  const msgInput   = document.getElementById('msgInput');
  const btnSend    = document.getElementById('btnSend');
  const btnListen  = document.getElementById('btnListen');
  const btnStop    = document.getElementById('btnStop');
  const canvas     = document.getElementById('spectrum');
  const debugLog   = document.getElementById('debugLog');
  const ctx        = canvas.getContext('2d');

  // ── State ──
  let audioCtx       = null;
  let analyser       = null;
  let micStream      = null;
  let isListening    = false;
  let isSending      = false;
  let animFrameId    = null;

  // Receiver state machine
  const RX_IDLE      = 0;
  const RX_RECEIVING = 1;
  let rxState        = RX_IDLE;
  let rxNibbles      = [];
  let lastDetected   = null;
  let lastDetectedAt = 0;
  let toneConfirm    = 0;  // consecutive frames with same tone
  const CONFIRM_FRAMES = 3; // require N consistent frames to accept a tone
  let silenceFrames  = 0;
  const SILENCE_NEEDED = 2;

  // ── Helpers ──
  function log(msg) {
    const line = document.createElement('div');
    line.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
    debugLog.appendChild(line);
    debugLog.scrollTop = debugLog.scrollHeight;
  }

  function setStatus(text, mode) {
    statusText.textContent = text;
    statusDot.className = 'status-dot' + (mode ? ' ' + mode : '');
  }

  function addMessage(text, type) {
    const div = document.createElement('div');
    div.className = 'msg ' + type;
    const body = document.createElement('div');
    body.textContent = text;
    const meta = document.createElement('div');
    meta.className = 'meta';
    meta.textContent = (type === 'sent' ? 'Sent' : 'Received') + ' at ' +
      new Date().toLocaleTimeString();
    div.appendChild(body);
    div.appendChild(meta);
    messagesEl.appendChild(div);
    messagesEl.scrollTop = messagesEl.scrollHeight;
  }

  function nibbleToFreq(n) {
    return FREQ_BASE + n * FREQ_STEP;
  }

  function freqToBin(freq, fftSize, sampleRate) {
    return Math.round(freq / (sampleRate / fftSize));
  }

  function binToFreq(bin, fftSize, sampleRate) {
    return bin * (sampleRate / fftSize);
  }

  // ── Audio Context Init ──
  function ensureAudioCtx() {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
    }
    if (audioCtx.state === 'suspended') {
      audioCtx.resume();
    }
    return audioCtx;
  }

  // ── Tone Generation ──
  function playTone(freq, durationMs) {
    return new Promise(resolve => {
      const ctx = ensureAudioCtx();
      const osc = ctx.createOscillator();
      const gain = ctx.createGain();

      osc.type = 'sine';
      osc.frequency.setValueAtTime(freq, ctx.currentTime);

      // Gentle ramp to avoid clicks
      gain.gain.setValueAtTime(0, ctx.currentTime);
      gain.gain.linearRampToValueAtTime(0.8, ctx.currentTime + 0.005);
      gain.gain.setValueAtTime(0.8, ctx.currentTime + durationMs / 1000 - 0.005);
      gain.gain.linearRampToValueAtTime(0, ctx.currentTime + durationMs / 1000);

      osc.connect(gain);
      gain.connect(ctx.destination);

      osc.start(ctx.currentTime);
      osc.stop(ctx.currentTime + durationMs / 1000 + 0.01);

      setTimeout(resolve, durationMs);
    });
  }

  function silence(durationMs) {
    return new Promise(resolve => setTimeout(resolve, durationMs));
  }

  async function transmitMessage(text) {
    if (isSending) return;
    isSending = true;
    btnSend.disabled = true;
    setStatus('Sending...', 'sending');
    log('TX: "' + text + '"');

    try {
      // START marker
      await playTone(FREQ_START, TONE_MS_MARKER);
      await silence(GAP_MS);

      // Encode each character
      const encoder = new TextEncoder();
      const bytes = encoder.encode(text);

      for (let i = 0; i < bytes.length; i++) {
        const byte = bytes[i];
        const highNibble = (byte >> 4) & 0x0F;
        const lowNibble  = byte & 0x0F;

        // High nibble
        await playTone(nibbleToFreq(highNibble), TONE_MS_NIBBLE);
        await silence(GAP_MS);

        // Low nibble
        await playTone(nibbleToFreq(lowNibble), TONE_MS_NIBBLE);
        await silence(GAP_MS);
      }

      // STOP marker
      await playTone(FREQ_STOP, TONE_MS_MARKER);

      addMessage(text, 'sent');
      log('TX complete');
    } catch (e) {
      log('TX error: ' + e.message);
    }

    isSending = false;
    btnSend.disabled = false;
    setStatus(isListening ? 'Listening' : 'Idle', isListening ? 'listening' : '');
  }

  // ── Microphone & Reception ──
  async function startListening() {
    try {
      ensureAudioCtx();

      micStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: SAMPLE_RATE
        }
      });

      const source = audioCtx.createMediaStreamSource(micStream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = FFT_SIZE;
      analyser.smoothingTimeConstant = 0.1;
      source.connect(analyser);

      isListening = true;
      rxState = RX_IDLE;
      rxNibbles = [];
      lastDetected = null;
      toneConfirm = 0;
      silenceFrames = 0;

      btnListen.disabled = true;
      btnStop.disabled = false;
      setStatus('Listening', 'listening');
      log('Listening started');

      pollSpectrum();
    } catch (e) {
      log('Mic error: ' + e.message);
      alert('Microphone access denied or unavailable.\n' + e.message);
    }
  }

  function stopListening() {
    isListening = false;
    if (micStream) {
      micStream.getTracks().forEach(t => t.stop());
      micStream = null;
    }
    if (animFrameId) {
      cancelAnimationFrame(animFrameId);
      animFrameId = null;
    }
    analyser = null;
    rxState = RX_IDLE;
    rxNibbles = [];

    btnListen.disabled = false;
    btnStop.disabled = true;
    setStatus('Idle', '');
    log('Listening stopped');
  }

  // ── Spectrum Analysis & Decoding ──
  function pollSpectrum() {
    if (!isListening || !analyser) return;

    const bufLen = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufLen);
    analyser.getByteFrequencyData(dataArray);

    const actualSampleRate = audioCtx.sampleRate;

    // Draw spectrum
    drawSpectrum(dataArray, bufLen, actualSampleRate);

    // Detect peak frequency in our band
    const detected = detectTone(dataArray, bufLen, actualSampleRate);

    processTone(detected);

    animFrameId = requestAnimationFrame(pollSpectrum);
  }

  function detectTone(data, bufLen, sampleRate) {
    // Find the bin range for our frequency band (17700 - 19600 Hz)
    const binLow  = freqToBin(17700, FFT_SIZE, sampleRate);
    const binHigh = freqToBin(19600, FFT_SIZE, sampleRate);

    let peakBin = -1;
    let peakVal = 0;

    for (let i = binLow; i <= binHigh && i < bufLen; i++) {
      if (data[i] > peakVal) {
        peakVal = data[i];
        peakBin = i;
      }
    }

    if (peakVal < DETECT_THRESHOLD) return null;

    const peakFreq = binToFreq(peakBin, FFT_SIZE, sampleRate);

    // Match against known frequencies
    // START
    if (Math.abs(peakFreq - FREQ_START) < FREQ_TOLERANCE) return 'START';
    // STOP
    if (Math.abs(peakFreq - FREQ_STOP) < FREQ_TOLERANCE) return 'STOP';
    // Nibbles
    for (let n = 0; n < NUM_NIBBLES; n++) {
      if (Math.abs(peakFreq - nibbleToFreq(n)) < FREQ_TOLERANCE) return n;
    }

    return null;
  }

  function processTone(detected) {
    const now = performance.now();

    if (detected === null) {
      // Silence frame
      silenceFrames++;
      toneConfirm = 0;
      lastDetected = null;

      // Timeout: if receiving and long silence, flush
      if (rxState === RX_RECEIVING && silenceFrames > 120) {
        flushReceived();
      }
      return;
    }

    silenceFrames = 0;

    // Confirm tone (same value for CONFIRM_FRAMES consecutive)
    if (detected === lastDetected) {
      toneConfirm++;
    } else {
      lastDetected = detected;
      toneConfirm = 1;
      return; // Wait for confirmation
    }

    if (toneConfirm !== CONFIRM_FRAMES) return;

    // Tone is confirmed — process once
    // (don't re-trigger until we see a gap/different tone)

    if (detected === 'START') {
      if (rxState === RX_IDLE) {
        rxState = RX_RECEIVING;
        rxNibbles = [];
        log('RX: START detected');
        setStatus('Receiving...', 'sending');
      }
    } else if (detected === 'STOP') {
      if (rxState === RX_RECEIVING) {
        flushReceived();
      }
    } else if (typeof detected === 'number' && rxState === RX_RECEIVING) {
      rxNibbles.push(detected);
      log('RX nibble: 0x' + detected.toString(16).toUpperCase());
    }

    // Prevent re-triggering same tone: bump confirm way past threshold
    toneConfirm = CONFIRM_FRAMES + 100;
  }

  function flushReceived() {
    rxState = RX_IDLE;
    setStatus(isListening ? 'Listening' : 'Idle', isListening ? 'listening' : '');

    if (rxNibbles.length < 2) {
      log('RX: too few nibbles, discarding');
      rxNibbles = [];
      return;
    }

    // Pair nibbles into bytes
    const bytes = [];
    for (let i = 0; i + 1 < rxNibbles.length; i += 2) {
      bytes.push((rxNibbles[i] << 4) | rxNibbles[i + 1]);
    }

    try {
      const decoder = new TextDecoder('utf-8', { fatal: false });
      const text = decoder.decode(new Uint8Array(bytes));
      if (text.length > 0) {
        addMessage(text, 'received');
        log('RX: "' + text + '"');
      }
    } catch (e) {
      log('RX decode error: ' + e.message);
    }

    rxNibbles = [];
  }

  // ── Spectrum Visualizer ──
  function drawSpectrum(data, bufLen, sampleRate) {
    const dpr = window.devicePixelRatio || 1;
    const w = canvas.clientWidth;
    const h = canvas.clientHeight;

    if (canvas.width !== w * dpr || canvas.height !== h * dpr) {
      canvas.width = w * dpr;
      canvas.height = h * dpr;
      ctx.scale(dpr, dpr);
    }

    ctx.clearRect(0, 0, w, h);

    // Background
    ctx.fillStyle = '#0d1117';
    ctx.fillRect(0, 0, w, h);

    // Draw only the ultrasonic band (17,700 - 19,600 Hz)
    const binLow  = freqToBin(17700, FFT_SIZE, sampleRate);
    const binHigh = freqToBin(19600, FFT_SIZE, sampleRate);
    const numBins = binHigh - binLow + 1;
    const barW = w / numBins;

    for (let i = 0; i < numBins; i++) {
      const bin = binLow + i;
      const val = data[bin] / 255;
      const barH = val * h;

      // Color: green for data band, blue for markers
      const freq = binToFreq(bin, FFT_SIZE, sampleRate);
      let color;
      if (freq < 18000) {
        color = `rgba(0, 150, 255, ${0.3 + val * 0.7})`;
      } else {
        const hue = 120 + (freq - 18000) / (19500 - 18000) * 60;
        color = `hsla(${hue}, 80%, ${30 + val * 40}%, ${0.4 + val * 0.6})`;
      }

      ctx.fillStyle = color;
      ctx.fillRect(i * barW, h - barH, barW - 0.5, barH);
    }

    // Overlay: detected tone indicator
    if (lastDetected !== null && silenceFrames < 3) {
      ctx.fillStyle = 'rgba(255,255,255,0.85)';
      ctx.font = '12px monospace';
      let label;
      if (lastDetected === 'START') label = 'START';
      else if (lastDetected === 'STOP') label = 'STOP';
      else label = '0x' + lastDetected.toString(16).toUpperCase();
      ctx.fillText('Tone: ' + label, 6, 14);
    }
  }

  // ── Event Handlers ──
  btnSend.addEventListener('click', () => {
    const text = msgInput.value.trim();
    if (!text) return;
    msgInput.value = '';
    transmitMessage(text);
  });

  msgInput.addEventListener('keydown', (e) => {
    if (e.key === 'Enter') btnSend.click();
  });

  btnListen.addEventListener('click', startListening);
  btnStop.addEventListener('click', stopListening);

  // Draw empty canvas on load
  function drawEmpty() {
    const dpr = window.devicePixelRatio || 1;
    const w = canvas.clientWidth;
    const h = canvas.clientHeight;
    canvas.width = w * dpr;
    canvas.height = h * dpr;
    ctx.scale(dpr, dpr);
    ctx.fillStyle = '#0d1117';
    ctx.fillRect(0, 0, w, h);
    ctx.fillStyle = '#334';
    ctx.font = '12px monospace';
    ctx.fillText('Spectrum will appear when listening...', 10, h / 2);
  }

  drawEmpty();
  log('Ready. Click "Start Listening" to begin.');
})();
</script>
</body>
</html>
